{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Transcripts4All/tools4all/blob/main/whisper-diarization.ipynb)"
      ],
      "metadata": {
        "id": "colab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1:\n",
        "# Execute the following task and upload an audio file, or files, to the content directory while you wait for the task to complete."
      ],
      "metadata": {
        "id": "step1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/MahmoudAshraf97/whisper-diarization\n",
        "!pip install git+https://github.com/SYSTRAN/faster-whisper.git ctranslate2==4.4.0\n",
        "!pip install \"nemo-toolkit[asr]>=2.dev\"\n",
        "!pip install git+https://github.com/MahmoudAshraf97/demucs.git\n",
        "!pip install git+https://github.com/oliverguhr/deepmultilingualpunctuation.git\n",
        "!pip install git+https://github.com/MahmoudAshraf97/ctc-forced-aligner.git"
      ],
      "metadata": {
        "id": "setup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_file = \"Sessao 1 2025-06-18 at 00.53.25.mp4\"\n"
      ],
      "metadata": {
        "id": "wdnugZ1VRMut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2:\n",
        "# ^ !!! WAIT FOR ABOVE TASK TO COMPLETE !!! ^\n",
        "# ^ !!! BEFORE RESTARTING RUNTIME !!! ^\n",
        "\n",
        "# Step 3:\n",
        "# Once the above task has completed and all audio files have successfully been uploaded to the content directory, execute the following task."
      ],
      "metadata": {
        "id": "step23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisperx.load_model(\"large-v2\", device)\n"
      ],
      "metadata": {
        "id": "xsTiNsOzRQ2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U whisperx"
      ],
      "metadata": {
        "id": "DveJKzJtRe1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisperx\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Usando dispositivo:\", device)"
      ],
      "metadata": {
        "id": "X3c5a7tPTPFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Instalar WhisperX\n",
        "!pip install -U whisperx\n",
        "\n",
        "# 2. Importar bibliotecas\n",
        "import whisperx\n",
        "import torch\n",
        "\n",
        "# 3. Definir dispositivo\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Usando:\", device)\n",
        "\n",
        "# 4. Carregar modelo de transcrição com qualidade alta\n",
        "model = whisperx.load_model(\"large-v2\", device)\n",
        "\n",
        "# 5. Transcrever o arquivo enviado\n",
        "audio_file = \"Sessao 1 2025-06-18 at 00.53.25.mp4\"\n",
        "result = model.transcribe(audio_file)\n",
        "\n",
        "# 6. Exibir um trecho da transcrição para confirmar\n",
        "for segment in result[\"segments\"][:5]:\n",
        "    print(f\"{segment['start']:.2f}s - {segment['end']:.2f}s: {segment['text']}\")\n"
      ],
      "metadata": {
        "id": "I2XAmOpWUxQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisperx.load_model(\"large-v2\", device, compute_type=\"int8\")\n"
      ],
      "metadata": {
        "id": "aGDqwS8rVUvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.transcribe(\"Sessao 1 2025-06-18 at 00.53.25.mp4\")\n"
      ],
      "metadata": {
        "id": "1gU7ors5VaED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WWcZiwIbVUIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisperx.load_model(\"large-v2\", device)\n"
      ],
      "metadata": {
        "id": "YLR1J1pUTZPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "P0ATe7klN3Dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n"
      ],
      "metadata": {
        "id": "f4OZoe3SPfjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, os\n",
        "audioFiles = glob.glob(\"/content/*.*\")\n",
        "os.chdir(\"/content/whisper-diarization\")\n",
        "for i in range(len(audioFiles)):\n",
        "  for audioFile in glob.glob(audioFiles[i]):\n",
        "    baseFile = os.path.splitext(audioFile)[0]\n",
        "    !python diarize_parallel.py --whisper-model large-v3 -a \"$audioFile\"\n",
        "    !rm \"$audioFile\"\n",
        "    !zip \"$baseFile\".zip \"$baseFile\".srt \"$baseFile\".txt\n",
        "    !rm \"$baseFile\".srt \"$baseFile\".txt"
      ],
      "metadata": {
        "id": "generate"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4:\n",
        "# Download the zip file, or files, from the content directory."
      ],
      "metadata": {
        "id": "step4"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}